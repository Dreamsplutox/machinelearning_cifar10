Layers;loss;optimizer;metrics;learningRate;epochs;batchSize;testName;indiv_id;valAccuracy;valLoss;trainAccuracy;trainLoss;runTime
"{'neurons': 2048, 'activation': 'sigmoid', 'dropOut': False, 'kernel_regularizer': False, 'activity_regularizer': False};{'neurons': 10, 'activation': 'sigmoid', 'dropOut': 0.3, 'kernel_regularizer': False, 'activity_regularizer': False};{'neurons': 512, 'activation': 'relu', 'dropOut': False, 'kernel_regularizer': 'regularizers.l2(0.0001)', 'activity_regularizer': False};{'neurons': 10, 'activation': 'softmax', 'dropOut': False, 'kernel_regularizer': 'regularizers.l1(0.0001)', 'activity_regularizer': False}";categorical_crossentropy;Adam(lr=0.0001);accuracy;0.0001;35;50;MLP with sigmoid layers 1 and 2 + relu layer 3 activation <=> regu l1 l2 and dropout;874553;0.10000000149011612;;0.1;;00:27:20
