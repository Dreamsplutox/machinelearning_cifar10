{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#987753\"><center>============= IMPORT DEPANDENCIES =============</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from random import randint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#987753\"><center>============= UTILS FUNCTION =============</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTime():\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H-%M-%S\")\n",
    "    today = str(date.today()).split('-')\n",
    "    today = today[2]+\"_\"+today[1]+\"_\"+today[0]\n",
    "    runTime = (\"%s_%s\" %(today,current_time))\n",
    "    return runTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logName():\n",
    "    \n",
    "    NAME = \"ModelCifar10_MLP_\"+str(ID)+\"_\"+getTime()\n",
    "    return NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParams():\n",
    "    \n",
    "    #model.add(Dense(64, input_dim=64, kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01)))\n",
    "    \n",
    "    modelParams = {\"Layers\":[{\"neurons\":64 , \"activation\":\"relu\",\"dropOut\":False, \"kernel_regularizer\":\"regularizers.l2(0.0001)\", \"activity_regularizer\":False},\n",
    "                    {\"neurons\":46 , \"activation\":\"relu\", \"dropOut\":0.3, \"kernel_regularizer\":False, \"activity_regularizer\":False},\n",
    "                    {\"neurons\":2500 , \"activation\":\"relu\", \"dropOut\":0.3, \"kernel_regularizer\":False, \"activity_regularizer\":False},\n",
    "                    {\"neurons\":10, \"activation\":\"softmax\", \"dropOut\":0.1, \"kernel_regularizer\":False, \"activity_regularizer\":False}],\n",
    "                   \"loss\":\"categorical_crossentropy\",\n",
    "                   \"optimizer\":\"Adam(lr=0.001)\",\n",
    "                   \"metrics\":\"accuracy\",\n",
    "                   \"learningRate\":.001,\n",
    "                   \"epochs\":50,\n",
    "                   \"batchSize\":500,\n",
    "                   \"testName\":\"Regu\"\n",
    "                 }\n",
    "    return modelParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humainesLabels(position):\n",
    "    labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    return labels[position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanizeTime(secs):\n",
    "    mins, secs = divmod(secs, 60)\n",
    "    hours, mins = divmod(mins, 60)\n",
    "    return ('RUN TIME : %02d:%02d:%02d' % (hours, mins, secs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    \n",
    "    (trainImages, trainLabels), (testImages, testLabels) = cifar10.load_data()\n",
    "    trainImages, testImages = trainImages / 255.0, testImages / 255.0\n",
    "    return trainImages, testImages, trainLabels, testLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFigure(images=False, labels=False, nbSamples=0, size=10):\n",
    "    \n",
    "    plt.figure(figsize=(size, size))\n",
    "    for i in range(nbSamples):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "       \n",
    "        plt.xlabel(humainesLabels(labels[i][0]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#987753\"><center>============= INIT MODEL =============</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHoteEncoding(trainLabels, testLabels):\n",
    "    \n",
    "    trainLabels = tf.keras.utils.to_categorical(trainLabels)\n",
    "    testLabels = tf.keras.utils.to_categorical(testLabels)\n",
    "    \n",
    "    return trainLabels, testLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(params):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "    for layers in params['Layers']:\n",
    "        \n",
    "        # ================ If kernel_regu & activity_regu == False ==============\n",
    "        if (layers['kernel_regularizer'] == False) and (layers['activity_regularizer'] == False):\n",
    "            model.add(Dense(layers['neurons'], activation=layers['activation']))\n",
    "        # ============================== End False ==============================\n",
    "        \n",
    "        # ================ If kernel_regu & activity_regu True ==============\n",
    "        elif (layers['kernel_regularizer'] == True) and (layers['activity_regularizer'] == True):\n",
    "            model.add(Dense(layers['neurons'], activation=layers['activation'], kernel_regularizer=layers['kernel_regularizer'], activity_regularizer=layers['activity_regularizer']))\n",
    "        \n",
    "        # ================ If kernel_regu = True ==============\n",
    "        elif (layers['kernel_regularizer'] == True) and (layers['activity_regularizer'] == False):\n",
    "            model.add(Dense(layers['neurons'], activation=layers['activation'], kernel_regularizer=layers['kernel_regularizer']))\n",
    "        \n",
    "        # ================ If kernel_regu & activity_regu True ==============\n",
    "        elif (layers['kernel_regularizer'] == False) and (layers['activity_regularizer'] == True):\n",
    "            model.add(Dense(layers['neurons'], activation=layers['activation'], activity_regularizer=layers['activity_regularizer']))\n",
    "            \n",
    "        # ================ If dropout ==============\n",
    "        if (layers['dropOut'] != False):\n",
    "            model.add(Dropout(layers['dropOut']))\n",
    "    \n",
    "    opt = Adam(lr=0.001, beta_1=0.9)\n",
    "    model.compile(loss=params['loss'],\n",
    "                   optimizer=opt,\n",
    "                   metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#987753\"><center>============= TRAIN MODEL =============</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeInput(trainImages, testImages):\n",
    "    \n",
    "    trainImages.reshape(trainImages.shape[0], trainImages.shape[1] * trainImages.shape[2] * trainImages.shape[3]) #\n",
    "    testImages.reshape(testImages.shape[0], testImages.shape[1] * testImages.shape[2] * testImages.shape[3]) #\n",
    "    \n",
    "    return trainImages, testImages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, params, trainImages, trainLabels, testImges, testLabels):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tensorboard = TensorBoard(log_dir='D:\\logsProject\\{}'.format(logName()))\n",
    "    ################################ CALCULATE RUNTIME - START ###############################\n",
    "    history = model.fit(trainImages, trainLabels,\n",
    "                       epochs=params['epochs'],\n",
    "                       batch_size=params['batchSize'], verbose=1, callbacks=[tensorboard], validation_data=(testImges, testLabels))\n",
    "    ################################ CALCULATE RUNTIME - END ###############################\n",
    "    print(humanizeTime(time.time() - start_time))\n",
    "    return model, humanizeTime(time.time() - start_time), history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#987753\"><center>============= EVALUATE MODEL =============</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, testImages, testLabels):\n",
    "    \n",
    "    return model.evaluate(testImages, testLabels, batch_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#987753\"><center>============= PREDICT =============</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionPercent(model, testImages, testLabels):\n",
    "    \n",
    "    prediction = model.predict(testImages)\n",
    "    predicted = []\n",
    "    for i in range(len(prediction)):\n",
    "        if np.argmax(testLabels[i]) == np.argmax(prediction[i]):\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)\n",
    "    print(\"Predicted percent {} %\".format((sum(predicted)/(len(predicted)) * 100)))\n",
    "    result = (sum(predicted)/len(predicted)) * 100\n",
    "    \n",
    "    return prediction, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPredictedResult(prediction, testImages, testLabels):\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(20):\n",
    "        plt.subplot(5,7,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(testImages[i])\n",
    "        plt.xlabel(\"True: \"+humainesLabels(np.argmax(testLabels[i]))+\"\\n\\n\\n\")\n",
    "        plt.title(\"\\nPredicted: \"+humainesLabels(np.argmax(prediction[i])))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#987753\"><center>============= SAVE MODEL =============</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, ID):\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H-%M-%S\")\n",
    "    today = str(date.today()).split('-')\n",
    "    today = today[2]+\"_\"+today[1]+\"_\"+today[0]\n",
    "    runTime = (\"%s_%s\" %(today,current_time))\n",
    "    model.save('D:\\Models\\model_run_'+runTime+\"_\"+str(ID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLogFile(path=\"D:/LogsProject/hyperParams/finalRecap.csv\", cols=None):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(path, sep=\";\" ,encoding='utf-8')\n",
    "        return df, path\n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        print('-Erorr file not found, it will be created now... \\n-Error tracback : %s' %(e))\n",
    "        f = open(path, \"w\")\n",
    "        writer = csv.DictWriter(f, fieldnames=cols)\n",
    "        writer.writeheader()\n",
    "        f.close()\n",
    "        df = pd.read_csv(path, sep=\",\" ,encoding='utf-8')\n",
    "        return df, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateExcelParams(params, history, resultEV, runTime):\n",
    "    \n",
    "    pass\n",
    "\n",
    "    params['indiv_id'] = ID\n",
    "    params['Layers'] = ';'.join(str(dict_) for dict_ in params['Layers'])\n",
    "    params['valAccuracy'] = resultEV[1]\n",
    "    params['valLoss'] = resultEV[0]\n",
    "    params['trainAccuracy'] = round(history.history['accuracy'][params['epochs']-1].item(), 3)\n",
    "    params['trainLoss'] = round(history.history['loss'][params['epochs']-1].item(), 3)\n",
    "    params['runTime'] = runTime.split(' ')[3]\n",
    "    \n",
    "    \n",
    "    dictToCsv = dict()\n",
    "    for key, value in zip(params.keys(), params.values()):\n",
    "        \n",
    "        tmp = []\n",
    "        tmp.append(value)\n",
    "        dictToCsv[key] = tmp\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(dictToCsv, columns=params.keys())\n",
    "    mainDirectory = os.getcwd() + \"\\\\logs\\\\mlp\\\\logs_\" + getTime()+\"\\\\\"\n",
    "    os.mkdir(mainDirectory)\n",
    "    df.to_csv(mainDirectory+\"combined_recap.csv\", sep=\";\", index=None, header=True)\n",
    "#     logFile, path = readLogFile(cols=params.keys())\n",
    "#     dfMerged = pd.concat([logFile, df], ignore_index=True)\n",
    "#     os.remove(path)\n",
    "#     dfMerged.to_csv(path, sep=\";\", index=None, header=True)\n",
    "\n",
    "#     return dfMerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global ID\n",
    "    ID = random.randint(1,1000000)\n",
    "    print(\"================================ ID RUN %s ================================\" % (ID))\n",
    "    params = hyperParams()\n",
    "    (trainImages, testImages, trainLabels, testLabels) = loadData()\n",
    "    \n",
    "    print(\"================================ SHAPE ================================\")\n",
    "    print(\"\\t- NB TRAIN SAMPLES %s WIDTH %s HEIGHT %s COLOR %s\" % (trainImages.shape))\n",
    "    print(\"\\t- NB TEST SAMPLES %s WIDTH %s HEIGHT %s COLOR %s\" % (testImages.shape))\n",
    "    \n",
    "    print(\"================================ PLOT FIGURE ================================\")\n",
    "    plotFigure(trainImages, trainLabels, nbSamples=25)\n",
    "    \n",
    "    print(\"================================ ONEHOT ENCODING ================================\")\n",
    "    trainLabels, testLabels = oneHoteEncoding(trainLabels, testLabels)\n",
    "    \n",
    "    print(\"================================ CREATE MODEL ================================\")\n",
    "    model = createModel(params)\n",
    "    \n",
    "    print(\"================================ RESHAPE INPUTS ================================\")\n",
    "    trainImages, testImages = reshapeInput(trainImages, testImages)\n",
    "    \n",
    "    print(\"================================ FIT MODEL ================================\")\n",
    "    model, runTime, history = fitModel(model, params, trainImages, trainLabels, testImages, testLabels)\n",
    "        \n",
    "    print(\"================================ EVALUATE MODEL ================================\")\n",
    "    resultEV = evaluateModel(model, testImages, testLabels)\n",
    "    \n",
    "    print(\"================================ PREDICITION ================================\")\n",
    "    prediction, result = predictionPercent(model, testImages, testLabels)\n",
    "    \n",
    "    print(\"================================ PLOT PREDICITION ================================\")\n",
    "    plotPredictedResult(prediction, testImages, testLabels)\n",
    "    \n",
    "    print(\"================================ SAVE MODEL ================================\")\n",
    "#     saveModel(model, ID)\n",
    "    \n",
    "    print(\"================================ GENERATE CSV HYPERPARAMS ================================\")\n",
    "    jsonDf = generateExcelParams(params, history, resultEV, runTime)\n",
    "#     jsonDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
